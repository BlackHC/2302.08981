{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40a1dd90",
   "metadata": {},
   "source": [
    "# Reproducing or downloading the benchmark results and running new configurations on the benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22754a6c",
   "metadata": {},
   "source": [
    "## Reproducing or downloading our results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad09446",
   "metadata": {},
   "source": [
    "In this notebook, we discuss how to reproduce the results from our paper and how to benchmark your own methods. Before running this notebook, please follow the installation and data download instructions from the README.md file of the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6daea8",
   "metadata": {},
   "source": [
    "We will now change the working directory from the examples subfolder to the main folder, which is required for the imports to work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54a9b9aa",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1db3753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')   # change directory inside the notebook to the main directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab1158a0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/blackhc/PycharmProjects/bmdal_reg_bbal\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41586197",
   "metadata": {},
   "source": [
    "## Running custom configurations on the benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3626a822",
   "metadata": {},
   "source": [
    "If you want to run your own configurations on the benchmark, you may want to take a look at the code in `run_experiments.py`. Here, we will show a minimalistic example of how to run two custom benchmark configurations, which can run on a CPU in a few minutes. A few other files you may find helpful are:\n",
    "- `test_single_task.py` allows you to run a single BMDAL configuration on a single split of a single data set, for fast exploration.\n",
    "- `rename_algs.py` contains a few helper functions to modify/rename/remove saved results. It can be used for example if the names of some experiment results should be changed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70779de2",
   "metadata": {},
   "source": [
    "First, we need to create a list of configurations that will be executed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4d04ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmdal_reg.run_experiments import RunConfigList\n",
    "from bmdal_reg.train import ModelTrainer\n",
    "from bmdal_reg.sklearn_models import RandomForestRegressor, VECatBoostRegressor, BaggingCatBoostRegressor, HistGradientBoostingRegressor\n",
    "\n",
    "# some general configuration for the NN and active learning\n",
    "kwargs = dict(post_sigma=1e-3, maxdet_sigma=1e-3, weight_gain=0.2, bias_gain=0.2, lr=0.375, act='relu')\n",
    "run_configs = RunConfigList()\n",
    "#run_configs.append(1e-6, ModelTrainer(f'NN_random', selection_method='random', create_model=RandomForestRegressor,\n",
    "                                   #base_kernel='linear', kernel_transforms=[], **kwargs))\n",
    "# run_configs.append(4e-6, ModelTrainer(f'HGR_lcmd-tp_predictions', selection_method='lcmd', sel_with_train=True, create_model=HistGradientBoostingRegressor,\n",
    "#                                              base_kernel='predictions', kernel_transforms=[], **kwargs))\n",
    "\n",
    "run_configs.append(4e-6, ModelTrainer(f'BagCAT_lcmd-tp_predictions', selection_method='lcmd', sel_with_train=True, create_model=BaggingCatBoostRegressor, n_models=20, base_kernel='predictions', kernel_transforms=[], **kwargs))\n",
    "# run_configs.append(4e-6, ModelTrainer(f'RF_lcmd-tp_predictions', selection_method='lcmd', sel_with_train=True, create_model=RandomForestRegressor,\n",
    "#                                              base_kernel='predictions', kernel_transforms=[], **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c93c8d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task ct has n_pool=41712, n_test=10700, n_features=379\n",
      "Task kegg_undir_uci has n_pool=50599, n_test=12921, n_features=27\n",
      "Running all configurations on split 0\n",
      "Start time: 2023-03-07 00:11:24\n",
      "Starting job 1/2 after 4s\n",
      "Starting job 2/2 after 4s\n",
      "Running BagCAT_lcmd-tp_predictions on split 0 of task kegg_undir_uci_64-128\n",
      "Running BagCAT_lcmd-tp_predictions on split 0 of task ct_64-128\n",
      "Test results: MAE=0.375327, RMSE=0.880426, MAXE=10.7209, q95=1.55912, q99=3.90023\n",
      "\n",
      "\n",
      "Performing AL step 1/2 with n_train=64, n_pool=50599, al_batch_size=64\n",
      "Test results: MAE=0.34153, RMSE=0.803987, MAXE=11.007, q95=1.37657, q99=3.41488\n",
      "\n",
      "\n",
      "Performing AL step 2/2 with n_train=128, n_pool=50535, al_batch_size=128\n",
      "Test results: MAE=0.313089, RMSE=0.726247, MAXE=11.3206, q95=1.24962, q99=2.24698\n",
      "\n",
      "\n",
      "Finished running BagCAT_lcmd-tp_predictions on split 0 of task kegg_undir_uci_64-128 on device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-33:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/blackhc/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/blackhc/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/blackhc/PycharmProjects/bmdal_reg_bbal/bmdal_reg/task_execution.py\", line 122, in __call__\n",
      "    self.result_queue.join()\n",
      "  File \"/home/blackhc/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/multiprocessing/queues.py\", line 331, in join\n",
      "    self._cond.wait()\n",
      "  File \"/home/blackhc/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/multiprocessing/synchronize.py\", line 261, in wait\n",
      "    return self._wait_semaphore.acquire(True, timeout)\n",
      "KeyboardInterrupt\n",
      "Process Process-32:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/blackhc/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/blackhc/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/blackhc/PycharmProjects/bmdal_reg_bbal/bmdal_reg/task_execution.py\", line 120, in __call__\n",
      "    result = f(*args)\n",
      "  File \"/home/blackhc/PycharmProjects/bmdal_reg_bbal/bmdal_reg/task_execution.py\", line 311, in __call__\n",
      "    result_dict = self.trainer(TaskSplit(self.task, id=self.split_id,\n",
      "  File \"/home/blackhc/PycharmProjects/bmdal_reg_bbal/bmdal_reg/train.py\", line 26, in __call__\n",
      "    return self.run_sklearn_model(task_split, device, do_timing)\n",
      "  File \"/home/blackhc/PycharmProjects/bmdal_reg_bbal/bmdal_reg/train.py\", line 79, in run_sklearn_model\n",
      "    model.fit(data.tensors['X'][train_idxs].cpu().numpy(), data.tensors['y'][train_idxs].cpu().numpy(),\n",
      "  File \"/home/blackhc/PycharmProjects/bmdal_reg_bbal/bmdal_reg/sklearn_models.py\", line 25, in fit\n",
      "    return self._fit(x, y.squeeze(-1), eval_x, eval_y.squeeze(-1))\n",
      "  File \"/home/blackhc/PycharmProjects/bmdal_reg_bbal/bmdal_reg/sklearn_models.py\", line 128, in _fit\n",
      "    self.model.fit(x, y)\n",
      "  File \"/home/blackhc/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py\", line 297, in fit\n",
      "    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
      "  File \"/home/blackhc/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py\", line 434, in _fit\n",
      "    all_results = Parallel(\n",
      "  File \"/home/blackhc/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/blackhc/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/blackhc/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/blackhc/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/blackhc/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/blackhc/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/blackhc/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/blackhc/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/site-packages/sklearn/utils/fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/blackhc/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py\", line 138, in _parallel_build_estimators\n",
      "    estimator_fit(X[:, features], y, sample_weight=curr_sample_weight)\n",
      "  File \"/home/blackhc/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/site-packages/catboost/core.py\", line 5730, in fit\n",
      "    return self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline,\n",
      "  File \"/home/blackhc/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/site-packages/catboost/core.py\", line 2355, in _fit\n",
      "    self._train(\n",
      "  File \"/home/blackhc/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/site-packages/catboost/core.py\", line 1759, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4623, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4672, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mbmdal_reg\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrun_experiments\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m run_experiments\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mbmdal_reg\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtrain\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ModelTrainer\n\u001B[0;32m----> 3\u001B[0m \u001B[43mrun_experiments\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexp_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtest_relu_small\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_config_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_configs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m                \u001B[49m\u001B[43mbatch_sizes_configs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtask_descs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m64-128\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_pool_for_normalization\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m                \u001B[49m\u001B[43mmax_jobs_per_device\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_train_initial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mds_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mct\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mkegg_undir_uci\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msequential_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m9\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/bmdal_reg_bbal/bmdal_reg/run_experiments.py:714\u001B[0m, in \u001B[0;36mrun_experiments\u001B[0;34m(exp_name, n_splits, run_config_list, batch_sizes_configs, task_descs, use_pool_for_normalization, max_jobs_per_device, n_train_initial, ds_names, sequential_split)\u001B[0m\n\u001B[1;32m    709\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m ram_gb_per_sample, trainer, ram_gb_per_sample_bs \u001B[38;5;129;01min\u001B[39;00m run_config_list:\n\u001B[1;32m    710\u001B[0m             runner\u001B[38;5;241m.\u001B[39madd(exp_name, split_id, tasks, ram_gb_per_sample, trainer, do_timing\u001B[38;5;241m=\u001B[39mdo_timing,\n\u001B[1;32m    711\u001B[0m                        warn_if_exists\u001B[38;5;241m=\u001B[39m(split_id \u001B[38;5;241m==\u001B[39m max_split_id),\n\u001B[1;32m    712\u001B[0m                        use_pool_for_normalization\u001B[38;5;241m=\u001B[39muse_pool_for_normalization,\n\u001B[1;32m    713\u001B[0m                        ram_gb_per_sample_bs\u001B[38;5;241m=\u001B[39mram_gb_per_sample_bs)\n\u001B[0;32m--> 714\u001B[0m \u001B[43mrunner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_all\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/bmdal_reg_bbal/bmdal_reg/task_execution.py:378\u001B[0m, in \u001B[0;36mJobRunner.run_all\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    374\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_all\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    375\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    376\u001B[0m \u001B[38;5;124;03m    Runs all jobs on the job scheduler.\u001B[39;00m\n\u001B[1;32m    377\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 378\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscheduler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_all\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjobs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/bmdal_reg_bbal/bmdal_reg/task_execution.py:279\u001B[0m, in \u001B[0;36mJobScheduler.run_all\u001B[0;34m(self, jobs)\u001B[0m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;66;03m# join all remaining processes\u001B[39;00m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m si \u001B[38;5;129;01min\u001B[39;00m started_infos:\n\u001B[0;32m--> 279\u001B[0m     \u001B[43msi\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mprocess\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    281\u001B[0m end_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m    282\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEnd time: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mutils\u001B[38;5;241m.\u001B[39mformat_date_s(end_time)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/bmdal_reg_bbal/bmdal_reg/task_execution.py:168\u001B[0m, in \u001B[0;36mFunctionProcess.pop_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpop_result\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    165\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;124;03m    :return: Returns the result and terminates the process, i.e., this function can only be called once.\u001B[39;00m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 168\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    169\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresult_queue\u001B[38;5;241m.\u001B[39mtask_done()\n\u001B[1;32m    170\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess\u001B[38;5;241m.\u001B[39mterminate()\n",
      "File \u001B[0;32m~/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/multiprocessing/queues.py:103\u001B[0m, in \u001B[0;36mQueue.get\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m block \u001B[38;5;129;01mand\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    102\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_rlock:\n\u001B[0;32m--> 103\u001B[0m         res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_recv_bytes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    104\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sem\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    105\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/multiprocessing/connection.py:216\u001B[0m, in \u001B[0;36m_ConnectionBase.recv_bytes\u001B[0;34m(self, maxlength)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m maxlength \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m maxlength \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnegative maxlength\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 216\u001B[0m buf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_recv_bytes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmaxlength\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m buf \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bad_message_length()\n",
      "File \u001B[0;32m~/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/multiprocessing/connection.py:414\u001B[0m, in \u001B[0;36mConnection._recv_bytes\u001B[0;34m(self, maxsize)\u001B[0m\n\u001B[1;32m    413\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_recv_bytes\u001B[39m(\u001B[38;5;28mself\u001B[39m, maxsize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 414\u001B[0m     buf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_recv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    415\u001B[0m     size, \u001B[38;5;241m=\u001B[39m struct\u001B[38;5;241m.\u001B[39munpack(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m!i\u001B[39m\u001B[38;5;124m\"\u001B[39m, buf\u001B[38;5;241m.\u001B[39mgetvalue())\n\u001B[1;32m    416\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m size \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/anaconda3/envs/bmdal_reg_bbal/lib/python3.10/multiprocessing/connection.py:379\u001B[0m, in \u001B[0;36mConnection._recv\u001B[0;34m(self, size, read)\u001B[0m\n\u001B[1;32m    377\u001B[0m remaining \u001B[38;5;241m=\u001B[39m size\n\u001B[1;32m    378\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m remaining \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 379\u001B[0m     chunk \u001B[38;5;241m=\u001B[39m \u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mremaining\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    380\u001B[0m     n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(chunk)\n\u001B[1;32m    381\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from bmdal_reg.run_experiments import run_experiments\n",
    "from bmdal_reg.train import ModelTrainer\n",
    "run_experiments(exp_name='test_relu_small', n_splits=2, run_config_list=run_configs,\n",
    "                batch_sizes_configs=[[64, 128]], task_descs=['64-128'], use_pool_for_normalization=True,\n",
    "                max_jobs_per_device=4, n_train_initial=64, ds_names=['ct', 'kegg_undir_uci'], sequential_split=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110ae1f6",
   "metadata": {},
   "source": [
    "Here, the meaning of the parameters is as follows:\n",
    "- `exp_name` is the name of the subfolder that the results will be saved at. This can be used to group experiments together, for example we used separate groups for relu and silu experiments in our paper.\n",
    "- `n_splits` is the number of random splits that the configurations should be run on. The random splits will be run in order. \n",
    "- `run_config_list` is the list of run configurations created previously.\n",
    "- `batch_sizes_configs` is a list of lists of batch sizes. In our case, we only have one batch size configuration, which is to acquire 64 samples in the first BMAL step and 128 samples in the second BMAL step. For experiments in our paper, we mostly used `batch_sizes_configs=[[256]*16]`.\n",
    "- `task_descs` is a corresponding list of suffixes for the task names. For example, here the data set `ct` combined with the batch size configuration `[64, 128]` will get the name `ct_64-128`. \n",
    "- `use_pool_for_normalization` specifies whether the dataset standardization should use statistics from the training and pool set or only from the training set. We used standardization only from the training set in our experiments, but especially for smaller initial training set sizes, it may be important to standardize also with the pool set.\n",
    "- `max_jobs_per_device` allows to specify a maximum number of jobs that are run in parallel on a single device (CPU or GPU). Fewer jobs may be executed in parallel if their estimated RAM usage (see above) would otherwise exceed the remaining RAM capacity (measured at the start of `run_experiments`).\n",
    "- `n_train_initial` specifies the initial training set size, which was 256 in our experiments.\n",
    "- `ds_names` specifies the names of the data sets that experiments should be run on. Possible names can be found in the data folder specified in `custom_paths.py`. By default, all 15 data sets from the benchmark are used.\n",
    "- `sequential_split` specifies the index of the random split for which `max_jobs_per_device=1` is used; the results from this split can then be used for runtime evaluation. By default, this is set to 9. Since we only use `n_splits=2` here, this case is not reached.\n",
    "\n",
    "Since the experiments above were run on a CPU, they took 5 minutes to complete, but this would be much faster on a GPU, especially with even higher `max_jobs_per_device`. If we ran this code again, it would notice that the results are already computed and would not recompute them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d019516f",
   "metadata": {},
   "source": [
    "Next, we want to evaluate the results. Unfortunately, we cannot directly use `run_evaluation.py` since its current implementation filters results by the suffix `256x16`, while our results use the suffix `64-128`. Therefore, we give a small example showing how to print a table for the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "46b149ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged results across tasks:\n",
      "Results for metric mae:\n",
      "CAT_lcmd-tp_predictions: -1.189 +- 0.016\n",
      "RF_lcmd-tp_predictions:  -1.070 +- 0.019\n",
      "NN_lcmd-tp_grad_rp-512:  -1.070 +- 0.019\n",
      "HGR_lcmd-tp_predictions: -0.968 +- 0.029\n",
      "\n",
      "Results for metric rmse:\n",
      "CAT_lcmd-tp_predictions: -0.557 +- 0.018\n",
      "RF_lcmd-tp_predictions:  -0.548 +- 0.020\n",
      "NN_lcmd-tp_grad_rp-512:  -0.548 +- 0.020\n",
      "HGR_lcmd-tp_predictions: -0.506 +- 0.011\n",
      "\n",
      "Results for metric q95:\n",
      "RF_lcmd-tp_predictions:  0.205 +- 0.028\n",
      "NN_lcmd-tp_grad_rp-512:  0.205 +- 0.028\n",
      "CAT_lcmd-tp_predictions: 0.217 +- 0.001\n",
      "HGR_lcmd-tp_predictions: 0.269 +- 0.025\n",
      "\n",
      "Results for metric q99:\n",
      "HGR_lcmd-tp_predictions: 0.730 +- 0.029\n",
      "RF_lcmd-tp_predictions:  0.761 +- 0.023\n",
      "NN_lcmd-tp_grad_rp-512:  0.761 +- 0.023\n",
      "CAT_lcmd-tp_predictions: 0.772 +- 0.049\n",
      "\n",
      "Results for metric maxe:\n",
      "RF_lcmd-tp_predictions:  1.371 +- 0.018\n",
      "NN_lcmd-tp_grad_rp-512:  1.371 +- 0.018\n",
      "HGR_lcmd-tp_predictions: 1.430 +- 0.019\n",
      "CAT_lcmd-tp_predictions: 1.582 +- 0.016\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bmdal_reg.evaluation.analysis import ExperimentResults, print_avg_results\n",
    "results = ExperimentResults.load('relu_small')\n",
    "print_avg_results(results, relative_to=None, filter_suffix='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fc7e2c",
   "metadata": {},
   "source": [
    "We can also print results on individual data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "682bd4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for task ct_64-128:\n",
      "Results for metric mae:\n",
      "NN_lcmd-tp_grad_rp-512: -1.573 +- 0.016\n",
      "NN_random:              -1.551 +- 0.010\n",
      "\n",
      "Results for metric rmse:\n",
      "NN_lcmd-tp_grad_rp-512: -1.176 +- 0.010\n",
      "NN_random:              -1.035 +- 0.011\n",
      "\n",
      "Results for metric q95:\n",
      "NN_lcmd-tp_grad_rp-512: -0.461 +- 0.012\n",
      "NN_random:              -0.257 +- 0.011\n",
      "\n",
      "Results for metric q99:\n",
      "NN_lcmd-tp_grad_rp-512: 0.139 +- 0.003\n",
      "NN_random:              0.396 +- 0.015\n",
      "\n",
      "Results for metric maxe:\n",
      "NN_lcmd-tp_grad_rp-512: 0.821 +- 0.039\n",
      "NN_random:              0.960 +- 0.009\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Results for task kegg_undir_uci_64-128:\n",
      "Results for metric mae:\n",
      "NN_lcmd-tp_grad_rp-512: -1.154 +- 0.201\n",
      "NN_random:              -0.961 +- 0.057\n",
      "\n",
      "Results for metric rmse:\n",
      "NN_lcmd-tp_grad_rp-512: -0.424 +- 0.136\n",
      "NN_random:              -0.161 +- 0.035\n",
      "\n",
      "Results for metric q95:\n",
      "NN_lcmd-tp_grad_rp-512: 0.310 +- 0.109\n",
      "NN_random:              0.435 +- 0.030\n",
      "\n",
      "Results for metric q99:\n",
      "NN_lcmd-tp_grad_rp-512: 1.016 +- 0.117\n",
      "NN_random:              1.280 +- 0.092\n",
      "\n",
      "Results for metric maxe:\n",
      "NN_lcmd-tp_grad_rp-512: 1.995 +- 0.185\n",
      "NN_random:              2.373 +- 0.011\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from evaluation.analysis import print_all_task_results\n",
    "print_all_task_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a25803",
   "metadata": {},
   "source": [
    "The results are saved using the folder structure `results_folder/exp_name/task_name/alg_name/split_idx/results.json`. For example, you can view the tasks we ran experiments on as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5fba3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ct_64-128', 'kegg_undir_uci_64-128']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import custom_paths\n",
    "os.listdir(Path(custom_paths.get_results_path()) / 'relu_small')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41904c0a",
   "metadata": {},
   "source": [
    "## Implementing your own methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5971d246",
   "metadata": {},
   "source": [
    "If you want to go beyond using our already implemented combinations of selection methods, kernels and kernel transformations, you have to make some modifications to the code such that your method can be used as above. Depending on how different your method is, we suggest three ways of including it:\n",
    "- If your method fits to our framework and simply provides new selection methods, kernels and/or kernel transformations, we suggest to extend `BatchSelector.select()` in `bmdal/algorithms.py` such that it can use your new component(s) given the corresponding configuration string(s).\n",
    "- If your method is a different BMDAL method that does not fit into our framework but does not require to modify the NN training process, you can modify the BMDAL part in `ModelTrainer.__call__()` in `train.py` such that it can call your method. While you could realize this by passing a custom BMDAL class or factory method directly to ModelTrainer, you should note that arguments to ModelTrainer are currently serialized to a JSON file, which is why we prefer using native data types like strings as arguments to ModelTrainer. This serialization of arguments to a JSON file can be helpful for example for automatically generating figure captions later on.\n",
    "- If you also want to modify the NN training process, you may want to change other code in ModelTrainer or replace it by your own custom class. Note that the NN model creation itself can be customized in ModelTrainer through the `create_model` argument."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-bmdal_reg_bbal-py",
   "language": "python",
   "display_name": "Python [conda env:bmdal_reg_bbal]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
